{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u8DP7RHp5-bL"
   },
   "source": [
    "###  Luis Ricardo Cruz García\n",
    "#### Procesamiento de Lenguaje Natural (NLP)\n",
    "\n",
    "#### Tarea 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PouC2cBJozyr",
    "outputId": "6b66b6d5-26f3-415d-fbb0-aef4b6234e3b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "\taccuracy_score, \n",
    "\tconfusion_matrix, \n",
    "\tf1_score, \n",
    "\tprecision_recall_fscore_support, \n",
    "\troc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l3VnSt_lpySm"
   },
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus: str, path_label: str) -> tuple[list, list]:\n",
    "\t\"\"\"Given the corpus and label paths, returns the list of docs and labels.\"\"\"\n",
    "\tdocs, labels = [], []\n",
    "\n",
    "\twith open(path_corpus, \"r\") as f_corpus:\n",
    "\t\tfor doc in f_corpus:\n",
    "\t\t\tdocs.append(doc)\n",
    "\n",
    "\twith open(path_label, \"r\") as f_labels:\n",
    "\t\tfor label in f_labels:\n",
    "\t\t\tlabels.append(label)\n",
    "\n",
    "\treturn docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xaF5C4_prbf0"
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\t\"\"\"Vocabulary class to store the frequencies and ranking of the words in the given corpus.\"\"\"\n",
    "\tdef __init__(self, corpus_words: list[str], n_words : int = 5000):\n",
    "\t\tcorpus_freqdist = nltk.FreqDist(corpus_words)  # frequency distribution\n",
    "\t\t\n",
    "\t\t# the n_words most occurring words\n",
    "\t\tself.vocabulary_word_freq = self._sort_FreqDist(corpus_freqdist)[:n_words]\n",
    "\n",
    "\t\tself.vocabulary = [word for word, freq in self.vocabulary_word_freq]\n",
    "\t\t\n",
    "\t\t# dictionary of the rank (frequency) of words in the vocabulary, word: freq_ranking\n",
    "\t\tself.word_to_index = {word: rank for rank, word in enumerate(self.vocabulary)}\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef _sort_FreqDist(fd: nltk.FreqDist) -> list:\n",
    "\t\t\"\"\"Return the list of items (pairs of <word, freq>) sorted by frequency (desc).\"\"\"\n",
    "\t\taux = list(fd.items())\n",
    "\t\taux.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\treturn aux\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.vocabulary)\n",
    "\t\n",
    "\tdef __getitem__(self, key: str) -> int:\n",
    "\t\treturn self.word_to_index[key]\n",
    "\n",
    "\tdef __contains__(self, key: str) -> bool:\n",
    "\t\treturn key in self.word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4KjVN8N6pyQI"
   },
   "outputs": [],
   "source": [
    "# get training docs and labels\n",
    "train_docs, train_labels = get_texts_from_file(\"../../Data/mex_train.txt\", \"../../Data/mex_train_labels.txt\")\n",
    "train_labels = list(map(int, train_labels))  # cast to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U0dCNNrDwsBc"
   },
   "outputs": [],
   "source": [
    "# get validation docs and labels\n",
    "val_docs, val_labels = get_texts_from_file(\"../../Data/mex_val.txt\", \"../../Data/mex_val_labels.txt\")\n",
    "val_labels = list(map(int, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pWPw3S30pyKn"
   },
   "outputs": [],
   "source": [
    "corpus_words = []\n",
    "for doc in train_docs:\n",
    "\tcorpus_words += tokenizer.tokenize(doc)\n",
    "\n",
    "# remove stopwords and set to lowercase\n",
    "set_stopwords = set(stopwords.words(\"spanish\"))\n",
    "corpus_words = [w.lower() for w in corpus_words if w not in set_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocabulary object for the 5000 most occurring words\n",
    "vocabulary_5k = Vocabulary(corpus_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DjIWFXyMGadw"
   },
   "source": [
    "## 2. Bolsas de Palabras, Bigramas y Emociones**\n",
    "\n",
    "Representa los documentos y clasifica con SVM similar a la Práctica 3, pero con diferentes pesados de términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bj3wilHux_ce"
   },
   "outputs": [],
   "source": [
    "parameters = {'C' : [0.05, 0.12, 0.25, 0.5, 1, 2, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_svm_model(train_BoW, validation_BoW, train_labels, max_iter=2000):\n",
    "\t\"\"\"Creates a linear SVM classification model and returns the prediction \n",
    "\tof labels for the validation BoW.\n",
    "\t\"\"\"\n",
    "\tsvm_lin_class = svm.LinearSVC(class_weight=\"balanced\", \n",
    "\t\t\t\t\t\t\t\t  max_iter=max_iter)\n",
    "\t\n",
    "\tgrid = GridSearchCV(\n",
    "\t\t\t\testimator=svm_lin_class, \n",
    "\t\t\t\tparam_grid=parameters, \n",
    "\t\t\t\tn_jobs=8, \n",
    "\t\t\t\tscoring=\"f1_macro\", \n",
    "\t\t\t\tcv=5)\n",
    "\t\n",
    "\tgrid.fit(train_BoW, train_labels)\n",
    "\t\n",
    "\ty_prediction = grid.predict(validation_BoW)\n",
    "\t\n",
    "\treturn y_prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aYo3CpFzGrZg"
   },
   "source": [
    "### 1. Evalue BoW (Bag of Words) con pesado binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0W9mRamv6guv"
   },
   "outputs": [],
   "source": [
    "def build_BoW_bin(docs: list[str], \n",
    "\t\t\t\t  vocabulary: Vocabulary) -> np.ndarray:\n",
    "\tBoW = np.zeros((len(docs), len(vocabulary)), dtype=float)\n",
    "\n",
    "\tfor i, doc in enumerate(docs):\n",
    "\t\tdoc_words = set(tokenizer.tokenize(doc))\n",
    "\t\tfor word in doc_words:\n",
    "\t\t\tif word in vocabulary:\n",
    "\t\t\t\tBoW[i, vocabulary[word]] = 1.\n",
    "\n",
    "\treturn BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OPiHGOFz6hMt"
   },
   "outputs": [],
   "source": [
    "train_BoW_bin = build_BoW_bin(train_docs, vocabulary_5k)\n",
    "val_BoW_bin = build_BoW_bin(val_docs, vocabulary_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_bin = prediction_svm_model(train_BoW_bin, val_BoW_bin, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[326  71]\n",
      " [ 64 155]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       397\n",
      "           1       0.69      0.71      0.70       219\n",
      "\n",
      "    accuracy                           0.78       616\n",
      "   macro avg       0.76      0.76      0.76       616\n",
      "weighted avg       0.78      0.78      0.78       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_bin)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_bin))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_sIawraV5IAD"
   },
   "source": [
    "### 2. Evalue BoW con pesado de frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Tm6OkdpFpiwV"
   },
   "outputs": [],
   "source": [
    "def build_BoW_freq(docs: list[str], \n",
    "\t\t\t\t   vocabulary: Vocabulary) -> np.ndarray:\n",
    "\tBoW = np.zeros((len(docs), len(vocabulary)), dtype=float)\n",
    "\n",
    "\tfor i, doc in enumerate(docs):\n",
    "\t\tfdist_docs = nltk.FreqDist(tokenizer.tokenize(doc))\n",
    "\t\tfor w in vocabulary.vocabulary:\n",
    "\t\t\tBoW[i, vocabulary[w]] = fdist_docs[w]\n",
    "\n",
    "\treturn BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YfR6maU76hyM"
   },
   "outputs": [],
   "source": [
    "train_BoW_freq = build_BoW_freq(train_docs, vocabulary_5k)\n",
    "val_BoW_freq = build_BoW_freq(val_docs, vocabulary_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_freq = prediction_svm_model(train_BoW_freq, val_BoW_freq, train_labels, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[328  69]\n",
      " [ 63 156]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       397\n",
      "           1       0.69      0.71      0.70       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.77      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_freq)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_freq))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RWVZbFsT6Jhh"
   },
   "source": [
    "### 3. Evalue BoW con pesado de tf-idf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$BoW = (w_{i,j})$, where\n",
    "$$w_{i,j} = \\operatorname{tf}(t_j, d_i) \\times \\log\\left(\\frac{N}{\\operatorname{df}(t_j)} \\right)$$\n",
    "where\n",
    "- $\\operatorname{tf}(t_j, d_i) =$ number of occurrences of term $t_j$ in document $d_j$. \n",
    "- $N =$ number documents. \n",
    "- $\\operatorname{df}(t_j) =$ number documents s.t. $t_j$ term is contained in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5Emp-cAf6kYQ"
   },
   "outputs": [],
   "source": [
    "def build_BoW_tfidf(docs: list[str], \n",
    "\t\t\t\t\tvocabulary: Vocabulary) -> np.ndarray:\n",
    "\tN = len(docs)\n",
    "\tBoW = np.zeros((len(docs), len(vocabulary)), dtype=float)\n",
    "\n",
    "\ttokenized_tweets = [tokenizer.tokenize(tweet) for tweet in docs]\n",
    "\tdf = [0] * len(vocabulary)\n",
    "\tfor i, w in enumerate(vocabulary.vocabulary):\n",
    "\t\tdf[i] = 1 + sum(1 for j in range(len(docs)) if w in tokenized_tweets[j])\n",
    "\n",
    "\tfor i, tweet in enumerate(docs):\n",
    "\t\tfdist_tweet = nltk.FreqDist(tokenized_tweets[i])\n",
    "\t\tfor j, w in enumerate(vocabulary.vocabulary):\n",
    "\t\t\tBoW[i, vocabulary[w]] = float(fdist_tweet[w]) * math.log(N / df[j])\n",
    "\n",
    "\treturn BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZJNYQL6X6kmE"
   },
   "outputs": [],
   "source": [
    "train_BoW_tfidf = build_BoW_tfidf(train_docs, vocabulary_5k)\n",
    "val_BoW_tfidf = build_BoW_tfidf(val_docs, vocabulary_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lrcg/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_pred_tfidf = prediction_svm_model(train_BoW_tfidf, val_BoW_tfidf, train_labels, max_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[328  69]\n",
      " [ 75 144]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       397\n",
      "           1       0.68      0.66      0.67       219\n",
      "\n",
      "    accuracy                           0.77       616\n",
      "   macro avg       0.74      0.74      0.74       616\n",
      "weighted avg       0.76      0.77      0.77       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_tfidf)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_tfidf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_xi-VaihFj0W"
   },
   "source": [
    "### 4. Evalue BoW con pesado binario normalizado $l_2$ (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6Zo-UMTa6lSx"
   },
   "outputs": [],
   "source": [
    "def l2_normalize(M: np.ndarray) -> np.ndarray:\n",
    "\t\"\"\"Normalize (using the l_2 norm) the rows of a rank-2 numpy array (matrix). \n",
    "\tReturns the matrix normalized.\n",
    "\t\"\"\"\n",
    "\treturn M * (1 / np.sqrt(np.square(M).sum(axis=1)[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BNicdL_56lg_"
   },
   "outputs": [],
   "source": [
    "train_BoW_bin_normalized = l2_normalize(train_BoW_bin)\n",
    "val_BoW_bin_normalized = l2_normalize(val_BoW_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_bin_normalized = prediction_svm_model(train_BoW_bin_normalized, val_BoW_bin_normalized, train_labels, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[328  69]\n",
      " [ 61 158]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       397\n",
      "           1       0.70      0.72      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.77      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_bin_normalized)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_bin_normalized))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s6f_s5GOGNQB"
   },
   "source": [
    "### 5. Evalue BoW con pesado frecuencia normalizado l2 (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4STnkPbrFzwY"
   },
   "outputs": [],
   "source": [
    "train_BoW_freq_normalized = l2_normalize(train_BoW_freq)\n",
    "val_BoW_freq_normalized = l2_normalize(val_BoW_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_freq_normalized = prediction_svm_model(train_BoW_freq_normalized, val_BoW_freq_normalized, train_labels, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[326  71]\n",
      " [ 61 158]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       397\n",
      "           1       0.69      0.72      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.77      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_freq_normalized)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_freq_normalized))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HxQouPiVJGnp"
   },
   "source": [
    "### 6. Evalué BoW con pesado tfidf normalizado l2 (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YR9-ZW_7F0W0"
   },
   "outputs": [],
   "source": [
    "train_BoW_tfidf_normalized = l2_normalize(train_BoW_tfidf)\n",
    "val_BoW_tfidf_normalized = l2_normalize(val_BoW_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_tfidf_normalized = prediction_svm_model(train_BoW_tfidf_normalized, val_BoW_tfidf_normalized, train_labels, max_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[320  77]\n",
      " [ 64 155]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       397\n",
      "           1       0.67      0.71      0.69       219\n",
      "\n",
      "    accuracy                           0.77       616\n",
      "   macro avg       0.75      0.76      0.75       616\n",
      "weighted avg       0.77      0.77      0.77       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_tfidf_normalized)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_tfidf_normalized))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nGOjeLytK9t_"
   },
   "source": [
    "### 7. Ponga una tabla comparativa a modo de resumen con las seis entradas anteriores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pizQppkkR3Dk"
   },
   "source": [
    "| | Binario | Frecuencia | tf-idf | Binario normalizado | Frecuencia normalizado | tf-idf normalizado |\n",
    "|--|---------------|----------------------|---------------|--|--|--|\n",
    "|Accuracy| 0.78 | 0.79 | 0.77 | 0.79 | 0.79 | 0.77|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OWSA1lNBLCc-"
   },
   "source": [
    "### 8. De las configuraciones anteriores elija la mejor y evalúela con más y menos términos (1000 y 7000 términos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n1Ty58iocjwx"
   },
   "source": [
    "La mejor configuración fue la de BoW con pesado de frecuencia, lo probaré con 7000 y 1000 términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_7k = Vocabulary(corpus_words, n_words=7000)\n",
    "vocabulary_1k = Vocabulary(corpus_words, n_words=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con 7000 términos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[333  64]\n",
      " [ 65 154]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       397\n",
      "           1       0.71      0.70      0.70       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.77      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_BoW_freq_7k = build_BoW_freq(train_docs, vocabulary_7k)\n",
    "val_BoW_freq_7k = build_BoW_freq(val_docs, vocabulary_7k)\n",
    "\n",
    "labels_pred_freq_7k = prediction_svm_model(train_BoW_freq_7k, val_BoW_freq_7k, train_labels, max_iter=3000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_freq_7k)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_freq_7k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con 1000 términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[329  68]\n",
      " [ 58 161]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       397\n",
      "           1       0.70      0.74      0.72       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.78      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_BoW_freq_1k = build_BoW_freq(train_docs, vocabulary_1k)\n",
    "val_BoW_freq_1k = build_BoW_freq(val_docs, vocabulary_1k)\n",
    "\n",
    "labels_pred_freq_1k = prediction_svm_model(train_BoW_freq_1k, val_BoW_freq_1k, train_labels, max_iter=10000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_freq_1k)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_freq_1k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A4vLFx1dLLw6"
   },
   "source": [
    "### 9. Utilice el recurso léxico del Consejo Nacional de Investigación de Canadá llamado \"EmoLex\" (https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) para construir una \"Bolsa de Emociones\" de los Tweets de agresividad (Debe usar EmoLex en Español). Para esto, una estrategia sencilla sería enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones (BoE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kxO-T0yBKYq6"
   },
   "outputs": [],
   "source": [
    "# get NRC data\n",
    "text_emotions = []\n",
    "with open(\"../../Data/Spanish-es-NRC-Emotion-Intensity-Lexicon-v1.txt\", \"r\") as file:\n",
    "\tfor line in file:\n",
    "\t\ttext_emotions += [line]\n",
    "\n",
    "# remove the first line (has no words)\n",
    "text_emotions = text_emotions[1:]\n",
    "\n",
    "word_emotion = {}\n",
    "for line in text_emotions:\n",
    "\ttmp = line.split(\"\\t\")\n",
    "\tword_emotion[tmp[1]] = tmp[2]\n",
    "\n",
    "emotion_index = {'anger': 0, \n",
    "\t\t\t\t 'anticipation': 1, \n",
    "\t\t\t\t 'disgust': 2, \n",
    "\t\t\t\t 'fear': 3, \n",
    "\t\t\t\t 'joy' : 4, \n",
    "\t\t\t\t 'sadness' : 5, \n",
    "\t\t\t\t 'surprise' : 6, \n",
    "\t\t\t\t 'trust' : 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_0BzbVbQqZUO"
   },
   "outputs": [],
   "source": [
    "def build_BoE(docs: list[str], \n",
    "\t\t\t  emotion_index: dict[str: int], \n",
    "\t\t\t  word_emotion: dict[str, str]):\n",
    "\tBoE = np.zeros((len(docs), len(emotion_index)))\n",
    "\n",
    "\tfor i, tweet in enumerate(docs):\n",
    "\t\ttweet_words = tokenizer.tokenize(tweet)\n",
    "\t\tfor word in tweet_words:\n",
    "\t\t\tif word in word_emotion:\n",
    "\t\t\t\t# frequency weight\n",
    "\t\t\t\tBoE[i, emotion_index[word_emotion[word]]] += 1\n",
    "\n",
    "\treturn BoE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n1blnWlML66-"
   },
   "source": [
    "### 10. Evalúa tú BoE clasificando con SVM. Ponga una tabla comparativa a modo de resumen con los tres pesados, normalize cada uno si lo cree conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ngafQfZ6KYEI"
   },
   "outputs": [],
   "source": [
    "train_BoE = build_BoE(train_docs, emotion_index, word_emotion)\n",
    "val_BoE = build_BoE(val_docs, emotion_index, word_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[202 195]\n",
      " [ 98 121]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58       397\n",
      "           1       0.38      0.55      0.45       219\n",
      "\n",
      "    accuracy                           0.52       616\n",
      "   macro avg       0.53      0.53      0.52       616\n",
      "weighted avg       0.57      0.52      0.53       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred_emotions = prediction_svm_model(train_BoE, val_BoE, train_labels, max_iter=10000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_emotions)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcxxsEdBYUDW"
   },
   "source": [
    "# 3 Recurso Lingüístico de Emociones Mexicano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SGQsDZf9YZRM"
   },
   "source": [
    "### 1. Utilice el recurso léxico llamado \"Spanish Emotion Lexicon (SEL)\" del Dr. Grigori Sidorov, profesor del Centro de Investigación en Computación (CIC) del IPN (http://www.cic.ipn.mx/∼sidorov/), para enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, tf, tfidf). Proponga alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento. Evalúa y escribe una tabla comparativa a modo de resumen con al menos tres pesados: binario, frecuencia, tfidf. Normalize cada pesado según lo crea conveniente de acuerdo al experimento (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "P7AjeXslYhup"
   },
   "outputs": [],
   "source": [
    "text_emotions_SEL = []\n",
    "with open(\"../../Data/SEL.txt\", \"r\", encoding='latin-1') as file:\n",
    "\tfor line in file:\n",
    "\t\ttext_emotions_SEL += [line]\n",
    "\n",
    "# remove the first line (has no words)\n",
    "text_emotions_SEL = text_emotions_SEL[1:]\n",
    "\n",
    "word_emotion_SEL = {}\n",
    "for line in text_emotions_SEL:\n",
    "\ttmp = line.split(\"\\t\")\n",
    "\tword_emotion_SEL[tmp[0]] = [tmp[2], tmp[1]]\n",
    "\n",
    "emotion_index_SEL = {'Alegría\\n': 0, \n",
    "\t\t\t\t\t 'Enojo\\n': 1, \n",
    "\t\t\t\t\t 'Miedo\\n': 2, \n",
    "\t\t\t\t\t 'Repulsión\\n': 3, \n",
    "\t\t\t\t\t 'Sorpresa\\n': 4, \n",
    "\t\t\t\t\t 'Tristeza\\n': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "KXuXNEM4M3KE"
   },
   "outputs": [],
   "source": [
    "def build_BoE_PFA(docs: list[str], \n",
    "\t\t\t\t  emotion_index: dict[str, int], \n",
    "\t\t\t\t  word_emotion: dict[str, str]) -> np.ndarray:\n",
    "\tBoE = np.zeros((len(docs), len(emotion_index)), dtype=float)\n",
    "\n",
    "\tfor i, tweet in enumerate(docs):\n",
    "\t\ttweet_words = tokenizer.tokenize(tweet)\n",
    "\t\tfor word in tweet_words:\n",
    "\t\t\tif word in word_emotion:\n",
    "\t\t\t\tBoE[i, emotion_index[word_emotion[word][0]]] += float(word_emotion[word][1])\n",
    "\n",
    "\treturn BoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "YPT9gndbsjxW"
   },
   "outputs": [],
   "source": [
    "train_BoE_SEL = build_BoE_PFA(train_docs, emotion_index_SEL, word_emotion_SEL)\n",
    "val_BoE_SEL = build_BoE_PFA(val_docs, emotion_index_SEL, word_emotion_SEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[358  39]\n",
      " [178  41]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77       397\n",
      "           1       0.51      0.19      0.27       219\n",
      "\n",
      "    accuracy                           0.65       616\n",
      "   macro avg       0.59      0.54      0.52       616\n",
      "weighted avg       0.61      0.65      0.59       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred_SEL = prediction_svm_model(train_BoE_SEL, val_BoE_SEL, train_labels, max_iter=2000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_SEL)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_SEL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YmvARMu5YiY1"
   },
   "source": [
    "### 2. En un comentario aparte, discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\". No más de 5 renglones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0Wk0Lm1588"
   },
   "source": [
    "Agregé la parte de PFA haciendo un tipo pesado de frecuencia en el cual le sumaba el PFA de cada palabra a la emoción que correspondía, creo es la forma más natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xwY9y053VIM"
   },
   "source": [
    "# 4 ¿Podemos mejorar con Bigramas?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MqLH9i8H3YCK"
   },
   "source": [
    "#### 1. Hacer un experimento dónde concatene una buena BoW según sus experimentos anteriores con otra BoW construida a partir de los 1000 bigramas más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "q3h-xg65Yk8I"
   },
   "outputs": [],
   "source": [
    "bigrams_corpus = list(bigrams(corpus_words))\n",
    "vocabulary_bigrams = Vocabulary(bigrams_corpus, n_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_BoW_with_bigrams_freq(docs: list[str], \n",
    "\t\t\t\t\t\t\t\tvocabulary: Vocabulary, \n",
    "\t\t\t\t\t\t\t\tvocabulary_bigrams: Vocabulary) -> np.ndarray:\n",
    "\tBoW_freq = build_BoW_freq(docs, vocabulary)\n",
    "\tBoW_bigrams_freq = build_BoW_freq(docs, vocabulary_bigrams)\n",
    "\treturn np.concatenate((BoW_freq, BoW_bigrams_freq), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BoW_with_bigrams_freq = build_BoW_with_bigrams_freq(train_docs, vocabulary_1k, vocabulary_bigrams)\n",
    "val_BoW_with_bigrams_freq = build_BoW_with_bigrams_freq(val_docs, vocabulary_1k, vocabulary_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[329  68]\n",
      " [ 58 161]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       397\n",
      "           1       0.71      0.72      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.78       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred_BoW_with_bigrams_freq = prediction_svm_model(train_BoW_with_bigrams_freq, val_BoW_with_bigrams_freq, train_labels, max_iter=10000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_BoW_with_bigrams_freq)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_BoW_with_bigrams_freq))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rhsr3Zqk3v4f"
   },
   "source": [
    "### 2. Hacer un experimento con las Bolsas de Emociones, Bolsa de Palabras y Bolsa de Bigramas; usted elige las dimensionalidades. Para construir la representación final del documento utilice la concatenación de las representaciones según sus observaciones (e.g., Bolsa de Palabras + Bolsa de Bigramas + Bolsa de Sentimientos de Canadá + Bolsa de Sentimientos de Grigori), y aliméntelas a un SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_BoW_with_bigrams_and_emotions_freq(docs: list[str], \n",
    "\t\t\t\t\t\t\t\t\t\t\t vocabulary: Vocabulary, \n",
    "\t\t\t\t\t\t\t\t\t\t\t vocabulary_bigrams: Vocabulary, \n",
    "\t\t\t\t\t\t\t\t\t\t\t emotion_index: dict[str, int], \n",
    "\t\t\t\t\t\t\t\t\t\t\t word_emotion: dict[str, str]) -> np.ndarray:\n",
    "\tBoW_freq = build_BoW_freq(docs, vocabulary)\n",
    "\tBoW_bigrams_freq = build_BoW_freq(docs, vocabulary_bigrams)\n",
    "\tBoE_PFA = build_BoE_PFA(docs, emotion_index, word_emotion)\n",
    "\treturn np.concatenate((BoW_freq, BoW_bigrams_freq, BoE_PFA), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BoW_with_bigrams_and_emotions_freq = build_BoW_with_bigrams_and_emotions_freq(train_docs, vocabulary_1k, vocabulary_bigrams, emotion_index_SEL, word_emotion_SEL)\n",
    "val_BoW_with_bigrams_and_emotions_freq = build_BoW_with_bigrams_and_emotions_freq(val_docs, vocabulary_1k, vocabulary_bigrams, emotion_index_SEL, word_emotion_SEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[328  69]\n",
      " [ 57 162]]\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       397\n",
      "           1       0.70      0.74      0.72       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.78      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred_BoW_with_bigrams_and_emotions_freq = prediction_svm_model(train_BoW_with_bigrams_and_emotions_freq, val_BoW_with_bigrams_and_emotions_freq, train_labels, max_iter=10000)\n",
    "\n",
    "print(f\"confusion matrix:\\n{confusion_matrix(val_labels, labels_pred_BoW_with_bigrams_and_emotions_freq)}\")\n",
    "print(\"-\" * 70)\n",
    "print(metrics.classification_report(val_labels, labels_pred_BoW_with_bigrams_and_emotions_freq))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IWoIjQxF3xLL"
   },
   "source": [
    "### 3. Elabore conclusiones sobre toda esta Tarea, incluyendo observaciones, comentarios y posibles mejoras futuras. Discuta el comportamiento de la BoW de usar solo palabras a integrar bigramas, y luego a integrar todo ¿ayudó? o ¿empeoró?. Discuta también brevemente el costo computacional de los experimentos ¿Valió la Pena tener todo?. Sea breve: todo en NO más de dos párrafos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta que, a pesar de que hay formas más complejas de representar a un documento (en este caso, un tweet) y que uno pensaría que estas capturan mejor el \"significado\" de un texto, en este caso, una de las formas más simples (una BoW con pesado de frecuencia y sólo 1000 términos) resultó ser la mejor (mayor accuracy) para clasificar los tweets agresivos.\n",
    "\n",
    "En cuanto a si valía la pena tener todo, depende, agregar los bigramas (a la BoW) resulto ser ligeramente menos efectivo (en accuracy) que una BoW con pesado de frecuencia (usando 1000 términos), así que no valió la pena, pero, al combinar BoW, BoE y bigramas el accuracy mejoró ligeramente (a sólo tener BoW y bigramas), pero esto sólo equiparó al mejor modelo obtenido previamente, el cual es más simple, así que es discutible el si valió la pena. \n",
    "\n",
    "Al final esta tarea deja ver que una idea simple puede ser la que mejor desempeño tiene, incluso superando ideas mucho más complejas que, en principio, uno podría pensar tienen mayor chance de capturar la complejidad de unos tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
